# ‚úÇÔ∏è Text Summarization using Hugging Face BART

This project demonstrates how to generate high-quality summaries from long text passages using a pre-trained **BART** model from Hugging Face Transformers. It's a minimal and effective NLP pipeline for abstractive summarization, suitable for news articles, research content, or documentation.

---

## üß† What is BART?

**BART** stands for **Bidirectional and Auto-Regressive Transformers** ‚Äî a model that combines the best of BERT (understanding context) and GPT (generating text). It is particularly well-suited for **sequence-to-sequence** tasks such as summarization and translation.

---

## üéØ Project Objective

To build a simple notebook that:
- Uses `facebook/bart-large-cnn` to summarize long-form input text
- Demonstrates how Hugging Face pipelines can be leveraged in seconds
- Can be easily extended into apps or APIs for real-world use

---

## üõ†Ô∏è Tech Stack

- Python
- [Hugging Face Transformers](https://huggingface.co/docs/transformers)
- Jupyter Notebook
